# Control Engineering

## Statistical Process Control (SPC)

SPC is the application of statistical methods to monitor and control the quality of a production process. This helps to ensure that the process operates efficiently, producing more specification-conforming products with less waste scrap. SPC can be applied to any process where the "conforming product" (product meeting specifications) output can be measured. Key tools used in SPC include [run charts](https://en.wikipedia.org/wiki/Run_chart), [control charts](https://en.wikipedia.org/wiki/Control_chart), a focus on [continuous improvement](https://en.wikipedia.org/wiki/Continuous_Improvement_Process), and [the design of experiments](https://en.wikipedia.org/wiki/Design_of_experiments). An example of a process where SPC is applied is manufacturing lines.

SPC must be practiced in two phases: The first phase is the initial establishment of the process, and the second phase is the regular production use of the process. In the second phase, a decision of the period to be examined must be made, depending upon the change in 5M&E conditions (Man, Machine, Material, Method, Movement, Environment) and wear rate of parts used in the manufacturing process (machine parts, jigs, and fixtures).

## Run-to-Run (R2R)

Run-to-run (R2R) control is a form of adaptive model-based process control that can be tailored to environments where the process is discrete, dynamic, and highly unobservable; this is characteristic of processes in the semiconductor manufacturing industry. It generally has, at its roots, a rather straightforward approach to adaptive model-based control such as a first-order linear plant model with moving average weighting applied to adapt the (zeroth-order) constant term in the model. Most of the complexity of R2R control science lies and will continue to lie in extensions to support practical application of R2R control in semiconductor manufacturing facilities of the future; these extensions include support for weighting and bounding of parameters, run-time modeling of a large number of disturbance types, and incorporating prediction information such as virtual metrology and yield prediction into the control solution.

## Fault Detection (FD)

**Fault detection, isolation, and recovery** (**FDIR**) is a subfield of control engineering which concerns itself with monitoring a system, identifying when a [fault](https://en.wikipedia.org/wiki/Fault_(technology)) has occurred, and pinpointing the type of fault and its location. Two approaches can be distinguished: A direct pattern recognition of sensor readings that indicate a fault and an analysis of the discrepancy between the sensor readings and expected values, derived from some model. In the latter case, it is typical that a fault is said to be detected if the discrepancy or *residual* goes above a certain threshold. It is then the task of fault isolation to categorize the type of fault and its location in the machinery. **Fault detection and isolation** (**FDI**) techniques can be broadly classified into two categories. These include model-based FDI and signal processing based FDI.

## Control Theory

Classical control theory is based on the use of mathematical models that describe the dynamics of a system using differential equations. These models can be represented by transfer functions, block diagrams, or state-space equations. Classical control theory focuses on the frequency domain analysis of system stability, response, and performance using tools such as Bode plots, Nyquist plots, and root locus. Classical control theory is useful for designing simple and robust controllers, such as proportional-integral-derivative (PID) controllers, that can handle linear and time-invariant systems.

Modern control theory is based on the use of advanced mathematical techniques that can handle nonlinear, time-varying, and uncertain systems. These techniques include optimal control, adaptive control, robust control, and nonlinear control. Modern control theory focuses on the state-space domain analysis of system controllability, observability, and optimality using tools such as Lyapunov functions, Hamilton-Jacobi equations, and Riccati equations. Modern control theory is useful for designing complex and adaptive controllers, such as model predictive control (MPC), sliding mode control (SMC), and neural network control (NNC), that can cope with system disturbances, uncertainties, and constraints.
